Congratulations, you have deployed the Kafka Spotguide to Kubernetes!
Your release is named `{{ .Release.Name }}`.

> Please note that if security scan was enabled for your cluster, running kafka for the first time may take longer than usual!
> Please be patient.

To run the commands below, the Kubernetes config needs to be set properly by running the following commands:

### Get the Kubernetes config

Download the cluster config from the cluster details page:
{{- if .Values.banzaicloud.cluster.id }}
[Cluster details]({{ .Values.banzaicloud.organization.name }}/cluster/{{ .Values.banzaicloud.cluster.id }}/details)
{{- end }}

```bash
export KUBECONFIG=<path to the file which contains the fetched config/downloaded before>
```

{{- if and .Values.banzaicloud.cluster (eq .Values.banzaicloud.cluster.distribution "eks") }}

In case of Amazon EKS a small authenticator program is required to be able to access the cluster. It can be installed using the following command:

Using Go:

```bash
go get -u -v github.com/kubernetes-sigs/aws-iam-authenticator/cmd/aws-iam-authenticator
```

Using the prebuilt binary:

Follow this documentation on Amazon how to get and install the prebuilt binary: [install aws-iam-authenticator for Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html#get-started-kubectl).

{{- end }}

To have access to the Kubernetes cluster, install the Kubernetes command-line tool: [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/).

### Accessing Kafka from outside of your Kubernetes cluster

To access Kafka outside of the Kubernetes cluster the `Loadbalancer` address needs to be retrieved:

External IP:

{{- if and .Values.banzaicloud.cluster (eq .Values.banzaicloud.cluster.distribution "eks") }}
```bash
export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} -o jsonpath="{.status.loadBalancer.ingress[0].hostname}" envoy-loadbalancer)

echo $SERVICE_IP
```
{{- end }}

{{- if and .Values.banzaicloud.cluster (not (eq .Values.banzaicloud.cluster.distribution "eks")) }}
```bash
export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} -o jsonpath="{.status.loadBalancer.ingress[0].ip}" envoy-loadbalancer)

echo $SERVICE_IP
```
{{- end }}

Ports:

```bash
export SERVICE_PORTS=($(kubectl get svc --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[*].port}" envoy-loadbalancer))

echo ${SERVICE_PORTS[@]}

# depending on the shell of your choice, arrays may be indexed starting from 0 or 1
export SERVICE_PORT=${SERVICE_PORTS[@]:0:1}

echo $SERVICE_PORT
```

> To save resources this Spotguide is using only one LoadBalancer to access all brokers and each broker is assigned to its own port For example: broker-0 will be available on port 19090, broker-1 on port 19091...

To try Kafka, we recommend you use [Kafkacat](https://github.com/edenhill/kafkacat).

__MacOS__:

```bash
brew install kafkacat
```

__Ubuntu__:

```bash
apt-get update
apt-get install kafkacat
```

Fetch Brokers metadata:

```bash
kafkacat -b $SERVICE_IP:$SERVICE_PORT -L
```

#### Run the sample WordCount Kafka Streams application

Download the following [jar](https://github.com/spotguides/kafka/raw/master/kafka-spotguide-example/target/kafka-spotguide-example-1.0-SNAPSHOT.jar) or
visit the [example](https://github.com/spotguides/kafka/tree/master/kafka-spotguide-example) repository and build the WordCount example.

Produce some message to topic `streams-plaintext-input`, run the downloaded jar and read the processed values from `streams-wordcount-output`:

> Kafkacat does not [support](https://github.com/edenhill/kafkacat/issues/89) common Kafka Java deserializers so Kafka consumer must be used to view the results created by the Kafka Streaming App.

```bash
kafkacat -P -b $SERVICE_IP:$SERVICE_PORT -t streams-plaintext-input

java -jar kafka-spotguide-example-1.0-SNAPSHOT.jar $SERVICE_IP:$SERVICE_PORT

./kafka-console-consumer.sh --topic streams-wordcount-output --from-beginning --bootstrap-server $SERVICE_IP:$SERVICE_PORT --property print.key=true --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer

```

### Using Kafka inside of Kubernetes

To use Kafka inside the cluster, create a Pod which contains `Kafkacat`.

The following command will create a `kafka-test` pod in the `{{ .Release.Namespace }}` namespace.

```bash
kubectl create -n {{ .Release.Namespace }} -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: kafka-test
spec:
  containers:
  - name: kafka-test
    image: solsson/kafkacat
    # Just spin & wait forever
    command: [ "/bin/bash", "-c", "--" ]
    args: [ "while true; do sleep 3000; done;" ]
EOF
```

Then exec into the container and produce and consume some messages:

```bash
kubectl exec -it -n {{ .Release.Namespace }} kafka-test bash

# Produce some message
kafkacat -P -b kafka-headless:29092 -t spotguide-kafka

# Consume them
kafkacat -C -b kafka-headless:29092 -t spotguide-kafka
```

{{- if .Values.banzaicloud.organization.name }}

### Monitoring

The monitoring dashboard can be accessed on the following host:

- [Grafana]({{ .Values.banzaicloud.organization.name }}/cluster/{{ .Values.banzaicloud.cluster.id }}/details)

### CI/CD Pipeline

Every time you make changes to the source code and update the `master` branch, the CI/CD pipeline will be triggered to reconfigure your Kafka cluster.

- [Go to CI/CD]({{ .Values.banzaicloud.organization.name }}/cicd/{{ include "repo-name" . }})

{{- end }}